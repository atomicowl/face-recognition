<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <title>Face Recognition</title>
    <style>
        #container {
          position: relative;
          width: 320px;
          height: 240px;
        }
        #video, #overlay {
          position: absolute;
          top: 0;
          left: 0;
          width: 320px;
          height: 240px;
          object-fit: fill; /* Ensures no cropping */
        }
        #overlay {
          pointer-events: none;
        }
        #result {
          font-weight: bold;
          margin-top: 10px;
        }
    </style>
</head>
<body>
<h1>Face Recognition</h1>

<div id="container">
    <video id="video" autoplay></video>
    <canvas id="overlay"></canvas>
</div>

<input type="text" id="nameInput" placeholder="Name for enrollment" />
<br /><br />
<button onclick="enrollFace()">Enroll</button>

<p id="result">Result: -</p>

<script>
    const video = document.getElementById('video');
    const overlay = document.getElementById('overlay');
    const ctx = overlay.getContext('2d');
    const result = document.getElementById('result');
    const captureCanvas = document.createElement('canvas');
    captureCanvas.width = 320;
    captureCanvas.height = 240;

    let isRecognizing = false;

    // Start webcam stream
    navigator.mediaDevices.getUserMedia({ video: true })
      .then(stream => {
        video.srcObject = stream;
      })
      .catch(err => {
        alert("Webcam access error: " + err.message);
      });

    function getSnapshotBlob() {
      const captureCtx = captureCanvas.getContext('2d');
      captureCtx.drawImage(video, 0, 0, captureCanvas.width, captureCanvas.height);
      return new Promise(resolve => {
        captureCanvas.toBlob(blob => resolve(blob), 'image/jpeg');
      });
    }

    function drawFaceRect(rect, name) {
      ctx.clearRect(0, 0, overlay.width, overlay.height);
      if (!rect) return;

      const rectY = rect.y - 60;
      ctx.strokeStyle = 'lime';
      ctx.lineWidth = 2;
      ctx.font = '16px Arial';
      ctx.fillStyle = 'lime';

      ctx.strokeRect(rect.x, rectY, rect.width, rect.height);

      const label = name || 'unidentified';
      const labelY = rectY > 20 ? rectY - 5 : rectY + 15;
      ctx.fillText(label, rect.x, labelY);
    }

    async function enrollFace() {
      const name = document.getElementById('nameInput').value.trim();
      if (!name) {
        alert('Please enter a name');
        return;
      }

      const blob = await getSnapshotBlob();
      const formData = new FormData();
      formData.append("name", name);
      formData.append("file", blob, "snapshot.jpg");

      try {
        const res = await fetch("http://localhost:8080/enroll", {
          method: "POST",
          body: formData
        });
        const json = await res.json();
        result.innerText = `Enrolled: ${json.name}`;
        drawFaceRect(null); // Clear overlay
      } catch (e) {
        alert("Enrollment failed");
      }
    }

    async function recognizeFaceLoop() {
      if (isRecognizing) return;
      isRecognizing = true;

      const blob = await getSnapshotBlob();
      const formData = new FormData();
      formData.append("file", blob, "snapshot.jpg");

      try {
        const res = await fetch("http://localhost:8080/recognize", {
          method: "POST",
          body: formData
        });
        const json = await res.json();

        result.innerText = `Recognized: ${json.name}`;
        drawFaceRect(json.rect, json.name);
      } catch (e) {
        console.error("Recognition failed:", e);
        drawFaceRect(null);
      }

      isRecognizing = false;
    }

    // Start recognition loop every 1 second
    setInterval(() => {
      recognizeFaceLoop();
    }, 500);
</script>
</body>
</html>
